{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_id_to_pathology_dict(file_path, pathologies, gt_header = False):\n",
    "    image_ids_to_pathologies = defaultdict(set)\n",
    "    pathologies = [pathology.lower() for pathology in pathologies]\n",
    "    with open(file_path, 'r') as f:\n",
    "        if gt_header:\n",
    "            header = f.readline() # skip header\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split(',')\n",
    "            for pathology in line[1:]:\n",
    "                if pathology.lower() in pathologies:\n",
    "                    image_ids_to_pathologies[line[0]].add(pathology.lower())\n",
    "                    \n",
    "\n",
    "    return image_ids_to_pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_matches(gt_dict, pred_dict):\n",
    "    exact_matches = 0\n",
    "    for k in gt_dict.keys():\n",
    "        if gt_dict[k] == pred_dict[k]:\n",
    "            exact_matches += 1\n",
    "\n",
    "    return exact_matches/len(gt_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VinDr specific code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr_test_split_ground_truth_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/VinDr-CXR/test_set_three_splits/VinDr_test_test_split_with_labels.csv\")\n",
    "xrv_224_chex_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/VinDr_evaluation_results/xrv_224_chex.txt\")\n",
    "xrv_224_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/VinDr_evaluation_results/xrv_224.txt\")\n",
    "xrv_512_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/VinDr_evaluation_results/xrv_512.txt\")    \n",
    "\n",
    "cheXpert_same_pathologies = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Lung Opacity\", \"Pleural Effusion\", \"Pneumothorax\", \"No finding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = build_image_id_to_pathology_dict(vindr_test_split_ground_truth_path, cheXpert_same_pathologies, gt_header = False)\n",
    "xrv_224_chex_predictions = build_image_id_to_pathology_dict(xrv_224_chex_path, cheXpert_same_pathologies)\n",
    "xrv_224_predictions = build_image_id_to_pathology_dict(xrv_224_path, cheXpert_same_pathologies)\n",
    "xrv_512_predictions = build_image_id_to_pathology_dict(xrv_512_path, cheXpert_same_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VinDr\n",
      "xrv_224_chex: 0.38402061855670105\n",
      "xrv_224: 0.19072164948453607\n",
      "xrv_512: 0.7654639175257731\n"
     ]
    }
   ],
   "source": [
    "# print accuracy i.e. the images where sets are equal\n",
    "print(\"VinDr\")\n",
    "print(f\"xrv_224_chex: {calculate_exact_matches(ground_truth, xrv_224_chex_predictions)}\")\n",
    "print(f\"xrv_224: {calculate_exact_matches(ground_truth, xrv_224_predictions)}\")\n",
    "print(f\"xrv_512: {calculate_exact_matches(ground_truth, xrv_512_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CheXpert evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_zeros_and_ones_to_written_form(file_path):\n",
    "    image_id_to_pathology_dict = defaultdict(set)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # create a list to store the pathologies\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_id = (\"/\").join(row['Path'].split('/')[-3:])  # Extract the image ID from the path\n",
    "        pathologies = {col.lower() for col in df.columns[-14:] if row[col] == 1.0} # Find pathologies for the current row\n",
    "        # if len(pathologies) == 0:\n",
    "        #     pathologies.add(\"no finding\")\n",
    "        # image_pathologies = image_pathologies.append({'Image_ID': image_id, 'Pathologies': pathologies}, ignore_index=True)\n",
    "        image_id_to_pathology_dict[image_id] = pathologies\n",
    "\n",
    "    return image_id_to_pathology_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_small_test_ground_truth_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/CheXpert/small/test.csv\")\n",
    "chexpert_small_valid_ground_truth_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/CheXpert/small/valid.csv\")\n",
    "\n",
    "chexpert_small_test_xrv_224_chex_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/test_set/xrv_224_chex.txt\")\n",
    "chexpert_small_test_xrv_224_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/test_set/xrv_224.txt\")\n",
    "chexpert_small_test_xrv_512_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/test_set/xrv_512.txt\")\n",
    "\n",
    "chexpert_small_valid_xrv_224_chex_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/validation_set/xrv_224_chex.txt\")\n",
    "chexpert_small_valid_xrv_224_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/validation_set/xrv_224.txt\")\n",
    "chexpert_small_valid_xrv_512_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/torchxrayvision/evaluations/CheXpert_evaluation_results/validation_set/xrv_512.txt\")\n",
    "\n",
    "\n",
    "all_cheXpert_pathologies = ['No Finding','Enlarged Cardiomediastinum','Cardiomegaly','Lung Opacity',\n",
    "        'Lung Lesion','Edema','Consolidation','Pneumonia','Atelectasis','Pneumothorax',\n",
    "        'Pleural Effusion','Pleural Other','Fracture','Support Devices']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_small_test_ground_truth = convert_zeros_and_ones_to_written_form(chexpert_small_test_ground_truth_path)\n",
    "chexpert_small_valid_ground_truth = convert_zeros_and_ones_to_written_form(chexpert_small_valid_ground_truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy of each model on test set\n",
    "chexpert_small_test_xrv_224_chex_predictions = build_image_id_to_pathology_dict(chexpert_small_test_xrv_224_chex_path, all_cheXpert_pathologies)\n",
    "chexpert_small_test_xrv_224_predictions = build_image_id_to_pathology_dict(chexpert_small_test_xrv_224_path, all_cheXpert_pathologies)\n",
    "chexpert_small_test_xrv_512_predictions = build_image_id_to_pathology_dict(chexpert_small_test_xrv_512_path, all_cheXpert_pathologies)\n",
    "\n",
    "# calculate accuracy of each model on validation set\n",
    "chexpert_small_valid_xrv_224_chex_predictions = build_image_id_to_pathology_dict(chexpert_small_valid_xrv_224_chex_path, all_cheXpert_pathologies)\n",
    "chexpert_small_valid_xrv_224_predictions = build_image_id_to_pathology_dict(chexpert_small_valid_xrv_224_path, all_cheXpert_pathologies)\n",
    "chexpert_small_valid_xrv_512_predictions = build_image_id_to_pathology_dict(chexpert_small_valid_xrv_512_path, all_cheXpert_pathologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheXpert Validation Set\n",
      "xrv_224_chex: 0.0811965811965812\n",
      "xrv_224: 0.0\n",
      "xrv_512: 0.14957264957264957\n",
      "CheXpert Test Set\n",
      "xrv_224_chex: 0.058383233532934134\n",
      "xrv_224: 0.011976047904191617\n",
      "xrv_512: 0.15718562874251496\n"
     ]
    }
   ],
   "source": [
    "print(\"CheXpert Validation Set\")   \n",
    "print(f\"xrv_224_chex: {calculate_exact_matches(chexpert_small_valid_ground_truth, chexpert_small_valid_xrv_224_chex_predictions)}\")\n",
    "print(f\"xrv_224: {calculate_exact_matches(chexpert_small_valid_ground_truth, chexpert_small_valid_xrv_224_predictions)}\")\n",
    "print(f\"xrv_512: {calculate_exact_matches(chexpert_small_valid_ground_truth, chexpert_small_valid_xrv_512_predictions)}\")\n",
    "\n",
    "print(\"CheXpert Test Set\")\n",
    "print(f\"xrv_224_chex: {calculate_exact_matches(chexpert_small_test_ground_truth, chexpert_small_test_xrv_224_chex_predictions)}\")\n",
    "print(f\"xrv_224: {calculate_exact_matches(chexpert_small_test_ground_truth, chexpert_small_test_xrv_224_predictions)}\")\n",
    "print(f\"xrv_512: {calculate_exact_matches(chexpert_small_test_ground_truth, chexpert_small_test_xrv_512_predictions)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
